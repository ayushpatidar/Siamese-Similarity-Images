{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://www.kaggle.com/xhlulu/shopee-siamese-resnet-50-image-only-submission?select=submission.csv](http://)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used above notebook as refrence. Thanks to [xhlulu](http:www.kaggle.com/xhlulu). \n",
    "\n",
    "I have added following major changes.\n",
    "* Used efficientnet_b3  model with different projecion head.\n",
    "* Used some data augmentation techniques for trainig  the network.\n",
    "* Used Groupkfold for splitting the data to avoid any leakage.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('/workspace/pytorch-image-models-master')\n",
    "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import random\n",
    "import cv2 \n",
    "import os\n",
    "import torch\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import TripletMarginLoss\n",
    "import timm\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../input/shopee-generate-data-for-triplet-loss/train_triplets_ids.csv'\n",
    "image_path = '../input/shopee-product-matching/train_images'\n",
    "batch_size= 8\n",
    "img_size = 256\n",
    "EPOCHS = 10\n",
    "SEED = 2020\n",
    "early_stopping = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge original data and siamese triplet data\n",
    "\n",
    "df = pd.read_csv(\"../input/shopee-generate-data-for-triplet-loss/train_triplets_imgs.csv\")\n",
    "\n",
    "cols = [i +\"_path\" for i in df.columns]\n",
    "\n",
    "df = df.rename(columns=dict(zip(df.columns,cols)))\n",
    "\n",
    "train = pd.concat([train, df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv(\"../input/shopee-product-matching/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train ,base[['posting_id', 'label_group']], left_on=['anchor'], right_on=['posting_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['label_group'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "def get_train_transforms():\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.HorizontalFlip(p=0.56),\n",
    "            albumentations.VerticalFlip(p=0.59),\n",
    "            albumentations.Rotate(limit=120, p=0.8),\n",
    "            albumentations.RandomBrightness(limit=(0.09, 0.6), p=0.5),\n",
    "#             albumentations.Cutout(num_holes=8, max_h_size=8, max_w_size=8, fill_value=0, always_apply=False, p=0.5),\n",
    "#             albumentations.ShiftScaleRotate(\n",
    "#                 shift_limit=0.25, scale_limit=0.1, rotate_limit=0\n",
    "#             ),\n",
    "            albumentations.Normalize(\n",
    "                MEAN, STD, max_pixel_value=255.0, always_apply=True\n",
    "            ),\n",
    "        \n",
    "            albumentations.Resize(img_size, img_size,always_apply=True),\n",
    "            ToTensorV2(p=1.0),\n",
    "            \n",
    "        ]\n",
    "    )\n",
    "\n",
    "def get_valid_transforms():\n",
    "\n",
    "    return albumentations.Compose([\n",
    "        albumentations.Resize(img_size, img_size,always_apply=True),\n",
    "        albumentations.Normalize(MEAN, STD, max_pixel_value=255.0, always_apply=True),\n",
    "        ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, aug):\n",
    "        self.df = df.values\n",
    "        self.aug = aug\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        data = dict()\n",
    "        # Read image\n",
    " \n",
    "        # anchor image\n",
    "        img_1 = self.df[index][3]\n",
    "        \n",
    "        # positive image\n",
    "        img_2 = self.df[index][4]\n",
    "        \n",
    "        # negative image\n",
    "        img_3 = self.df[index][5]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        image_1 = cv2.imread(f'{image_path}/{img_1}')\n",
    "        image_2 = cv2.imread(f'{image_path}/{img_2}')\n",
    "        image_3 = cv2.imread(f'{image_path}/{img_3}')\n",
    "        \n",
    "        \n",
    "        image_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB)\n",
    "        image_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2RGB)\n",
    "        image_3 = cv2.cvtColor(image_3, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        \n",
    "            \n",
    "        image_1 = self.aug(image=image_1)['image']\n",
    "        image_2 = self.aug(image=image_2)['image']\n",
    "        image_3 = self.aug(image=image_3)['image']\n",
    "        \n",
    "#         image_1 = image_1.permute(2,1,0)\n",
    "#         image_2 = image_2.permute(2,1,0)\n",
    "        \n",
    "        \n",
    "        data['image_1'] = image_1\n",
    "        data['image_2'] = image_2\n",
    "        data['image_3'] = image_3\n",
    "        \n",
    "        \n",
    "        \n",
    "        return data\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model('efficientnet_b3', pretrained=True)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Identity()\n",
    "        self.model.global_pool =  nn.Identity()\n",
    "        \n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classfier = nn.Sequential(nn.Linear(n_features, 1024),\n",
    "                                       nn.Dropout(0.48),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(1024, 512))\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        output = self.model(input)\n",
    "        output = self.pooling(output).view(input.shape[0], -1)\n",
    "        #print(\"shape after pooling\",output.shape)\n",
    "        output = self.classfier(output)\n",
    "        #print(\"shape after classification layer\", output.shape)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdoel = ShopeeModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ContrastiveLoss(nn.Module):\n",
    "#     def __init__(self, margin=0.58):\n",
    "#         super(ContrastiveLoss, self).__init__()\n",
    "#         self.margin = margin\n",
    "        \n",
    "    \n",
    "#     def forward(self, output1, output2, output3):\n",
    "        \n",
    "#         euclied_dist  = F.pairwise_distance(output1, output2)\n",
    "#         label = 0\n",
    "#         loss_p = ((1-label)*(torch.pow(euclied_dist,2)))+(label*torch.clamp(self.margin-torch.pow(euclied_dist,2), min=0.0))\n",
    "#         loss_p = loss_p/2\n",
    "         \n",
    "#         euclied_dist  = F.pairwise_distance(output1, output3)\n",
    "        \n",
    "#         label = 1\n",
    "#         loss_n = ((1-label)*(torch.pow(euclied_dist,2)))+(label*torch.clamp(self.margin-torch.pow(euclied_dist,2), min=0.0))\n",
    "#         loss_n = loss_n/2\n",
    "        \n",
    "#         loss = torch.cat([loss_p, loss_n],axis=0)\n",
    "#         return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(train_dataloader, model, opt, scheduler):\n",
    "    \n",
    "    lis = list()\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        \n",
    "        image_1 = batch['image_1'].to(device)\n",
    "        image_2 = batch['image_2'].to(device)\n",
    "        image_3 = batch['image_3'].to(device)\n",
    "        \n",
    "        output_1 = model(image_1)\n",
    "        output_2 = model(image_2)\n",
    "        output_3 = model(image_3)\n",
    "        \n",
    "        #criterion = ContrastiveLoss().to(device)\n",
    "        criterion = TripletMarginLoss(margin=0.58).to(device)\n",
    "        loss = criterion(output_1, output_2, output_3)\n",
    "        \n",
    "        loss.backward()\n",
    "        if (step+1)%4 == 0:\n",
    "            opt.step()\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            if step == len(train_dataloader):\n",
    "                opt.step()\n",
    "                scheduler.step()\n",
    "        \n",
    "        lis.append(loss.item())\n",
    "        \n",
    "    return lis\n",
    "\n",
    "def valid_fn(valid_dataloader, model):\n",
    "    \n",
    "    lis = list()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embed = torch.Tensor().to(device)\n",
    "        labels = torch.Tensor().to(device)\n",
    "        for step, batch in enumerate(valid_dataloader):\n",
    "\n",
    "\n",
    "\n",
    "            image_1 = batch['image_1'].to(device)\n",
    "            image_2 = batch['image_2'].to(device)\n",
    "            image_3 = batch['image_3'].to(device)\n",
    "\n",
    "            output_1 = model(image_1)\n",
    "            output_2 = model(image_2)\n",
    "            output_3 = model(image_3)\n",
    "\n",
    "\n",
    "            #criterion = ContrastiveLoss().to(device)\n",
    "            criterion = TripletMarginLoss(margin=0.58).to(device)\n",
    "            loss = criterion(output_1, output_2, output_3)\n",
    "\n",
    "            lis.append(loss.item())\n",
    "            \n",
    "            \n",
    "        \n",
    "    return lis\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "def run(fold):\n",
    "    early_stopping = 4\n",
    "    \n",
    "    train1 = train[train['fold']!=fold]\n",
    "    valid = train[train['fold']==fold]\n",
    "    \n",
    "    train1 = train1.reset_index(drop=True)\n",
    "    valid = valid.reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = ShopeeDataset(train1, get_train_transforms())\n",
    "    train_dataloder = DataLoader(train_dataset, \n",
    "              shuffle=True,\n",
    "              batch_size=batch_size,\n",
    "              num_workers=4,\n",
    "              drop_last=False)\n",
    "    \n",
    "    \n",
    "    valid_dataset = ShopeeDataset(valid, get_valid_transforms())\n",
    "    valid_dataloader = DataLoader(valid_dataset, \n",
    "              shuffle=False,\n",
    "              batch_size=16,\n",
    "              num_workers=3,\n",
    "              drop_last=False)\n",
    "    \n",
    "    model = ShopeeModel().to(device)\n",
    "    \n",
    "    # Freezing layer\n",
    "    model.model.requires_grad = False\n",
    "    \n",
    "    # Making laster layer of convolution as traianble\n",
    "    for name,parameter in list(model.children())[0].named_parameters():\n",
    "        if name =='conv_head.weight':\n",
    "            print(name)\n",
    "            parameter.requires_grad = True\n",
    "            \n",
    "    opt = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001, weight_decay= 0.001)\n",
    "    scheduler = CosineAnnealingWarmRestarts(opt, T_0=10, verbose=False)\n",
    "    \n",
    "    best_loss = 100000\n",
    "    for epochs in range(EPOCHS):\n",
    "        loss_ep = train_fn(train_dataloder, model, opt, scheduler)\n",
    "        print(\"Train Loss for epoch\", (epochs,sum(loss_ep)/len(loss_ep)))\n",
    "        \n",
    "        valid_loss_ep = valid_fn(valid_dataloader, model)\n",
    "        results[epochs] = valid_loss_ep\n",
    "        print(\"Valid Loss for epoch\", (epochs,sum(valid_loss_ep)/len(valid_loss_ep)))\n",
    "        \n",
    "        if sum(valid_loss_ep)/len(valid_loss_ep)<best_loss:\n",
    "            early_stopping = 4\n",
    "            torch.save(model.state_dict(), str(sum(valid_loss_ep)/len(valid_loss_ep))+\"_\"+str(fold)+\"_\"+ str(epochs)+\".pth\")\n",
    "        else:\n",
    "            early_stopping = early_stopping-1\n",
    "            \n",
    "        if early_stopping==0:\n",
    "            print(\".....early_stopping....\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=2)\n",
    "groups = train['label_group'].tolist()\n",
    "\n",
    "for ind, (train_index, val_index) in enumerate(gkf.split(train, train['label_group'], groups)):\n",
    "    train.loc[val_index, 'fold'] = int(ind)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "print(train.groupby(['fold', 'label_group']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to computaional constraints training only one fold.\n",
    "for fold in [1,0]:\n",
    "    run(fold)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
